[{"authors":["admin"],"categories":null,"content":"I am a PhD candidate in the Intelligent Sensory Information Systems group at the University of Amsterdam, advised by Prof. Marcel Worring. My current research focus is representation learning on graph-structured data, in particular multimodal learning using hypergraphs.\nI have worked on developing graph based deep learning models that are scalable to datasets with many modalities, with applications in recommedner systems, link predictions and neuroimaging. I am also part of the ASGARD project, whose aim is to develop AI powered solutions for forensic investigations that can directly contribute towards the Law Enforcement Agencies (LEAs) technological autonomy across EU.\nI graduated from Indian Institute of Technology, Kanpur in 2015 with a B.Tech-M.Tech dual degree in Electrical Engineering. My formal background is in speech signal processing. I worked on developing Voice Activity Detection (VAD) algorithms during my master\u0026rsquo;s thesis and during my internship at NTU Singapore.\n","date":1461110400,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1555459200,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I am a PhD candidate in the Intelligent Sensory Information Systems group at the University of Amsterdam, advised by Prof. Marcel Worring. My current research focus is representation learning on graph-structured data, in particular multimodal learning using hypergraphs.\nI have worked on developing graph based deep learning models that are scalable to datasets with many modalities, with applications in recommedner systems, link predictions and neuroimaging. I am also part of the ASGARD project, whose aim is to develop AI powered solutions for forensic investigations that can directly contribute towards the Law Enforcement Agencies (LEAs) technological autonomy across EU.","tags":null,"title":"Devanshu Arya","type":"authors"},{"authors":["**Devanshu Arya**","Richard Olij","Deepak K. Gupta","Ahmed El Gazzar","Guido van Wingen","Marcel Worring","Rajat Mani Thomas"],"categories":null,"content":" Further details on your publication can be written here using Markdown for formatting. This text will be displayed on the Publication Detail page. ","date":1580428800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1580428800,"objectID":"d0ed6f0463864c33b46c397bc0e316f7","permalink":"/publication/midl_2020/","publishdate":"2020-01-31T00:00:00Z","relpermalink":"/publication/midl_2020/","section":"publication","summary":"Geometric deep learning methods such as graph convolutional networks have recently proven to deliver generalized solutions in disease prediction using medical imaging. In this paper, we focus particularly on their use in autism classification. Most of the recent methods use graphs to leverage phenotypic information about subjects (patients or healthy controls) as additional contextual information. To do so, metadata such as age, gender and acquisition sites are utilized to define intricate relations (edges) between the subjects. We alleviate the use of such non-imaging metadata and propose a fully imaging-based approach where information from structural and functional Magnetic Resonance Imaging (MRI) data are fused to construct the edges and nodes of the graph. To characterize each subject, we employ brain summaries. These are 3D images obtained from the 4D spatiotemporal resting-state fMRI data through summarization of the temporal activity of each voxel using neuroscientifically informed temporal measures such as amplitude low frequency fluctuations and entropy. Further, to extract features from these 3D brain summaries, we propose a 3D CNN model. We perform analysis on the open dataset for autism research (full ABIDE I-II) and show that by using simple brain summary measures and incorporating sMRI information, there is a noticeable increase in the generalizability and performance values of the framework as compared to state-of-the-art graph-based models.","tags":null,"title":"Fusing Structural and Functional MRIs using Graph Convolutional Networks for Autism Classification","type":"publication"},{"authors":["Dirk Streeb","**Devanshu Arya**","Daniel Keim","Marcel Worring"],"categories":null,"content":" Further details on your publication can be written here using Markdown for formatting. This text will be displayed on the Publication Detail page. ","date":1571529600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1571529600,"objectID":"26cd26ebf385513cb1cbfce68ca1c4c8","permalink":"/publication/ieee_vis_2019/","publishdate":"2019-10-20T00:00:00Z","relpermalink":"/publication/ieee_vis_2019/","section":"publication","summary":"Members of communities often share topics of interest. However, usually not all members are interested in all topics, and participation in topics changes over time. Prediction models based on temporal hypergraphs that—in contrast to state-of-the-art models—exploit group structures in the communication network can be used to anticipate changes of interests. In practice, there is a need to assess these models in detail. While loss functions used in the training process can provide initial cues on the model’s global quality, local quality can be investigated with visual analytics. In this paper, we present a visual analytics framework for the assessment of temporal hypergraph prediction models. We introduce its core components: a sliding window approach to prediction and an interactive visualization for partially fuzzy temporal hypergraphs.","tags":null,"title":"Visual Analytics Framework for the Assessment of Temporal Hypergraph Prediction Models","type":"publication"},{"authors":["**Devanshu Arya**","Stevan Rudinac","Marcel Worring"],"categories":null,"content":" Further details on your publication can be written here using Markdown for formatting. This text will be displayed on the Publication Detail page. ","date":1571097600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1571097600,"objectID":"f049432644542741efdeb3fa6b5bf016","permalink":"/publication/acm_mm_bni_2019/","publishdate":"2019-10-15T00:00:00Z","relpermalink":"/publication/acm_mm_bni_2019/","section":"publication","summary":"Multimodal datasets contain an enormous amount of relational information, which grows exponentially with the introduction of new modalities.  Learning representations in such a scenario is inherently complex due to the presence of multiple heterogeneous information channels. These channels can encode both (a) inter-relations between the items of different modalities and (b) intra-relations between the items of the same modality. Encoding multimedia items into a continuous low-dimensional semantic space such that both types of relations are captured and preserved is extremely challenging, especially if the goal is a unified end-to-end learning framework. The two key challenges that need to be addressed are: 1) the framework must be able to merge complex intra and inter relations without losing any valuable information and 2) the learning model should be invariant to the addition of new and potentially very different modalities. In this paper, we propose a flexible framework which can scale to data streams from many modalities. To that end we introduce a hypergraph-based model for data representation and deploy Graph Convolutional Networks to fuse relational information within and across modalities. Our approach provides an efficient solution for distributing otherwise extremely computationally expensive or even unfeasible training processes across multiple-GPUs, without any sacrifices in accuracy. Moreover, adding new modalities to our model requires only an additional GPU unit keeping the computational time unchanged, which brings representation learning to truly multimodal datasets. We demonstrate the feasibility of our approach in the experiments on multimedia datasets featuring second, third and fourth order relations.","tags":null,"title":"HyperLearn: A Distributed Approach for Representation Learning in Datasets With Many Modalities","type":"publication"},{"authors":["Sarah Ibrahimi","Shuo Chen","**Devanshu Arya**","Arthur Câmara","Yunlu Chen","Tanja Crijns","Maurits Van Der Goes","Thomas Mensink","Emiel Van Miltenburg","Daan Odijk","William Thong","Jiaojiao Zhao","Pascal Mettes"],"categories":null,"content":" Further details on your publication can be written here using Markdown for formatting. This text will be displayed on the Publication Detail page. ","date":1571097600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1571097600,"objectID":"1acac3ff7d7fed14d61e6382aa6b743a","permalink":"/publication/acm_mm_demo_2019/","publishdate":"2019-10-15T00:00:00Z","relpermalink":"/publication/acm_mm_demo_2019/","section":"publication","summary":"This demo presents a system for journalists to explore video footage for broadcasts. Daily news broadcasts contain multiple news items that consist of many video shots and searching for relevant footage is a labor intensive task. Without the need for annotated video shots, our system extracts semantics from footage and automatically matches these semantics to query terms from the journalist. The journalist can then indicate which aspects of the query term need to be emphasized, eg the title or its thematic meaning. The goal of this system is to support the journalists in their search process by encouraging interaction and exploration with the system.","tags":null,"title":"Interactive exploration of journalistic video footage through multimodal semantic matching","type":"publication"},{"authors":["**Devanshu Arya**","Stevan Rudinac","Marcel Worring"],"categories":null,"content":" Further details on your publication can be written here using Markdown for formatting. This text will be displayed on the Publication Detail page. ","date":1567555200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567555200,"objectID":"f7caf6698c4101d71008e0e5d92ca7a8","permalink":"/publication/cbmi_2019/","publishdate":"2019-09-04T00:00:00Z","relpermalink":"/publication/cbmi_2019/","section":"publication","summary":"Online discussion forums provide open workspace allowing users to share information, exchange ideas, address problems, and form groups. These forums feature multimodal posts and analyzing them requires a framework that can integrate heterogeneous information extracted from the posts, i.e. text, visual content and the information about user interactions with the online platform and each other. In this paper, we develop a generic framework that can be trained to identify communication behavior and patterns in relation to an entity of interest, be it user, image or text in internet forums. As the case study we use the analysis of violent online political extremism content, which has been a major challenge for domain experts. We demonstrate the generalizability and flexibility of our framework in predicting relational information between multimodal entities by conducting extensive experimentation around four practical use cases.","tags":null,"title":"Predicting Behavioural Patterns in Discussion Forums using Deep Learning on Hypergraphs","type":"publication"},{"authors":["**Devanshu Arya**","Marcel Worring"],"categories":null,"content":" Further details on your publication can be written here using Markdown for formatting. This text will be displayed on the Publication Detail page. ","date":1527811200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1527811200,"objectID":"7dec624ddcc43cf1979df4b59cd40948","permalink":"/publication/icmr_2018/","publishdate":"2018-06-01T00:00:00Z","relpermalink":"/publication/icmr_2018/","section":"publication","summary":"Online social networks are constituted by a diverse set of entities including users, images and posts which makes the task of predicting interdependencies between entities challenging. We need a model that transfers information from a given type of relations between entities to predict other types of relations, irrespective of the type of entity. In order to devise a generic framework, one needs to capture the relational information between entities without any entity dependent information. However, there are two challenges: (a) a social network has an intrinsic community structure. In these communities, some relations are much more complicated than pairwise relations, thus cannot be simply modeled by a graph; (b) there are different types of entities and relations in a social network, taking into account all of them makes it difficult to formulate a model. In this paper, we claim that representing social networks using hypergraphs improves the task of predicting missing information about an entity by capturing higher-order relations. We study the behavior of our method by performing experiments on CLEF dataset consisting of images from Flickr, an online photo sharing social network.","tags":null,"title":"Exploiting Relational Information in Social Networks using Geometric Deep Learning on Hypergraphs","type":"publication"},{"authors":["Devanshu Arya"],"categories":null,"content":"","date":1461110400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1555459200,"objectID":"6557c3168efbb91db68d01effdaeba8b","permalink":"/post/acm_mm_bni/","publishdate":"2016-04-20T00:00:00Z","relpermalink":"/post/acm_mm_bni/","section":"post","summary":"Our paper titled HyperLearn A Distributed Approach for Representation Learning in Datasets With Many Modalities  has been accepted as Brave New Idea at ACM Multimedia","tags":["Academic"],"title":"August 2019 - Our paper titled HyperLearn A Distributed Approach for Representation Learning in Datasets With Many Modalities has been accepted as Brave New Idea at ACM Multimedia","type":"post"},{"authors":["Devanshu Arya"],"categories":null,"content":"","date":1461110400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1555459200,"objectID":"7702655c1c2ce1cb3b7082f17f78efcc","permalink":"/post/talk/","publishdate":"2016-04-20T00:00:00Z","relpermalink":"/post/talk/","section":"post","summary":"","tags":["Academic"],"title":"August 2019 - Our paper titled HyperLearn A Distributed Approach for Representation Learning in Datasets With Many Modalities has been accepted as Brave New Idea at ACM Multimedia","type":"post"},{"authors":["Devanshu Arya"],"categories":null,"content":"","date":1461110400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1555459200,"objectID":"7f15084f2aab4c55718570480cf7c261","permalink":"/post/talk_2/","publishdate":"2016-04-20T00:00:00Z","relpermalink":"/post/talk_2/","section":"post","summary":"","tags":["Academic"],"title":"August 2019 - Our paper titled HyperLearn A Distributed Approach for Representation Learning in Datasets With Many Modalities has been accepted as Brave New Idea at ACM Multimedia","type":"post"},{"authors":["Devanshu Arya"],"categories":null,"content":"","date":1461110400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1555459200,"objectID":"aa20be3ad614156cdb47941637d3a0bd","permalink":"/post/asgard/","publishdate":"2016-04-20T00:00:00Z","relpermalink":"/post/asgard/","section":"post","summary":"Our paper titled HyperLearn A Distributed Approach for Representation Learning in Datasets With Many Modalities has been accepted as Brave New Idea at ACM Multimedia","tags":["Academic"],"title":"August 2019 - Our paper titled HyperLearn A Distributed Approach for Representation Learning in Datasets With Many Modalities has been accepted as Brave New Idea at ACM Multimedia ","type":"post"},{"authors":["**Devanshu Arya**","Anant Raj","Rajesh Hegde"],"categories":null,"content":" Further details on your publication can be written here using Markdown for formatting. This text will be displayed on the Publication Detail page. ","date":1377388800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1377388800,"objectID":"47dc9d83f6c8c8a8b82559e9e5406fb2","permalink":"/publication/interspeech_2013/","publishdate":"2013-08-25T00:00:00Z","relpermalink":"/publication/interspeech_2013/","section":"publication","summary":"The significance of varying the height and bandwidth of the group delay spectrum is hitherto unexplored in the spectral reconstruction of speech signals. In this paper, a family of variable height-bandwidth filters are designed to evaluate their performance in the reconstruction of speech. The design procedure for higher order group delay filters as a cascade of second order filters is first described. These higher order filters enable the synthesis of speech sounds by simultaneously varying the height and bandwidth of the group delay spectrum. The group delay filter response is corrected by removing zeros in close proximity to the unit circle which give rise to abrupt phase transitions at points of significant excitation. Experiments on spectral reconstruction and perception of speech using variable height bandwidth group delay filters are conducted to compute the optimal height and bandwidth of the group delay filter. The experimental results indicate that the optimal height bandwidth obtained from a family of variable height bandwidth group delay filters does indeed improve the spectral reconstruction and perception of speech sounds when compared to fixed height bandwidth group delay filters.","tags":null,"title":"Significance of variable height-bandwidth group delay filters in the spectral reconstruction of speech","type":"publication"}]